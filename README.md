# VisionNet: CIFAR-10 Image Classifier from Scratch

ğŸš€ Built entirely with PyTorch
ğŸ—ï¸ Deep CNN + Residual Blocks
ğŸ“ˆ Achieves **81% test accuracy** on CIFAR-10 (v4.0)

---

## ğŸ” Architecture Overview

A fully custom convolutional neural network designed for image classification:

* 3 convolutional blocks (32 â†’ 64 â†’ 128 filters)
* 2 residual blocks (ResNet-style)
* BatchNorm, ReLU, MaxPooling in each block
* Global Average Pooling + Fully Connected head
* Data augmentation: RandomCrop, HorizontalFlip
* Training on CPU (GPU-ready)

---

## ğŸ“Š Experiment Results

| Version | Accuracy | Notes                                     |
| ------- | -------- | ----------------------------------------- |
| v2.1    | 0.79     | Baseline CNN + BatchNorm                  |
| v3.0    | 0.79     | Added data augmentation                   |
| v3.1    | 0.79     | Added LR scheduler                        |
| v4.0    | **0.81** | Added residual blocks, global avg pooling |

---

## ğŸ§ª Run It Yourself

### Install dependencies

```bash
pip install -r requirements.txt
```

### Train the model

```bash
python train.py
```

### Evaluate a saved model

```bash
python evaluate.py --model outputs/cifar10_cnn_v4.0.pth
```

---

## ğŸ“ Project Structure

```
visionnet/
â”œâ”€â”€ models/                # VisionCNN architecture variants
â”‚   â””â”€â”€ vision_cnn_v4.py
â”œâ”€â”€ data/                  # CIFAR-10 loading + transforms
â”‚   â””â”€â”€ cifar_loader.py
â”œâ”€â”€ utils/                 # Training and evaluation helpers
â”‚   â”œâ”€â”€ training.py
â”‚   â””â”€â”€ evaluation.py
â”œâ”€â”€ outputs/               # Saved models and plots
â”œâ”€â”€ experiments.md         # Logged metrics per version
â”œâ”€â”€ train.py               # Training script
â”œâ”€â”€ evaluate.py            # Evaluation + classification report
â”œâ”€â”€ requirements.txt       # Dependencies
â””â”€â”€ README.md              # Project overview (this file)
```

---

## ğŸ“¦ Features

* Clean modular codebase
* Easy to swap model versions
* Auto-logging to `experiments.md`
* Classification report after evaluation

---

## ğŸ§  Future Work

* Add SE attention blocks (v4.1?)
* Add transfer learning baseline
* Enable mixed-precision training with AMP (once GPU-ready)

---

## ğŸ License

MIT License

